;===================================================================
;                          Subclusters
;===================================================================

; For each subcluster, add a new subcluster section.
; Each subcluster name must be unique for the entire grid, so make sure to not
; pick anything generic like "MAIN".  Each subcluster section must start with
; the words "Subcluster", and cannot be named "CHANGEME".

; There should be one subcluster section per set of homogeneous nodes in the
; cluster.

; This data is used to determine where OSG pilot jobs can be sent, so it's
; important to keep it up to date.

; If you have many similar subclusters, then feel free to collapse them into
; larger, approximately-correct groups.

; See example below:

;[Subcluster CHANGEME]
; should be the name of the subcluster
;name = SUBCLUSTER_NAME
; Megabytes of RAM per node.
;ram_mb = MB_OF_RAM
; Number of cores per node.
;cores_per_node = #_CORES_PER_NODE
; A list of VOs that are allowed to submit to this subcluster;
; If *, uses VOs that have accounts on this CE
;allowed_vos = vo1, vo2

; Non-mandatory attributes
; The maximum wall-clock time a job is allowed to run on this subcluster,
; in minutes.  Leave blank or set to 0 to indicate no wall time limit on jobs.
;max_wall_time = 1440
; The queue which jobs should be submitted to in order to run on this resource.
; Equivalent to the HTCondor grid universe classad attribute "remote_queue"
;queue = blue
; Transformation attributes which the HTCondor job router should apply to
; incoming jobs so they can run on this resource, as per
; http://research.cs.wisc.edu/htcondor/manual/v8.3/5_4HTCondor_Job.html
; These are in HTCondor classad syntax, and should be used sparingly.
;extra_transforms = [ set_WantRHEL6 = 1; ]


[Subcluster PRP SDSC]
name = PRP SDSC
ram_mb = 4110
cores_per_node = 1
allowed_vos = "OSG, IceCube, GLOW"
max_wall_time = 0


